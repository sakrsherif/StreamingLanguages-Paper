\subsection{Data Variety}

Data variety refers to the presence of different data formats, data types, data semantics and associated data management solutions within the scope of an information system. The term emerged with the advent of Big Data, but the problem of taming variety is well known in Computer Science that also refers to it when discussing: machine understanding of unstructured data such as text, images and video as well as (syntactic, structural and semantic) interoperability and data integration for structured and semistructured data. 

Taming data variety is per se a problem that can be solved, even in presence of volume, in multiple ways for few data sources, but it is still unsolved when the data sources to integrate are hundreds or more as well as when the data to integrate is highly dynamic or even flowing (as in the scope of this paper).

\textbf{Why is this important?}

Increasingly, applications require real-time processing of heterogeneous data streams together with large background knowledge bases. Consider, for instance, the following two examples taken from~\cite{DellAglioDataScience2017}. 

In the first example, we want to use the sensor readings of the last 10 minutes to find electricity-producing turbines that are in a state similar (i.e., Pearson correlated by at least 0.75) to any turbine that subsequently had a critical failure. To understand the data variety, consider that a electricity-producing plan may have tens of turbine of 3-4 different types that are equipped with different sensors deployed other many years and more sensors will deployed in the future. Moreover, in many cases, once an anomaly is detected, the user also needs to retrieve multimedia maintenance instructions and annotations to complete the diagnosis process. 

In the first example, we want to use the latest open traffic information and social media as well as the weather forecast to determine if the users of a mobile mobility app are likely to run into a traffic jam during their commute tonight and how long it will take them to go home? To understand the data variety, image that the data the app owner bases this analysis on comes from third parties that are free to evolve syntax, structure and semantics.

There are many more examples that highlight the opportunity to create value by taming variety and velocity simultaneously. In social media analytics, it would be extremely valuable to identifying the current top influencers that are driving the discussion about the top emerging topics across all the social networks. In the tourism industry, it would be valuable to tell tourist where they can spend their evening given the presence of people and what their doing (predicted analysing the spatio-temporal correlation between privacy-preserving aggregates of Mobile Telecom Data and of geo-located Social Media posts). In well-being analytics, I would be worth advising people when to go exercising, given their past, possibly sedentary, behaviour and allergies (accessed in a privacy-preserving manner) as well as current weather conditions and pollution/allergen levels.

\textbf{How can we measure the challenge?}
The streaming language data variety challenge can be broken down
into the following measures $\mathbf{C_4}$--$\mathbf{C_6}$:

\begin{itemize}
  \item[$\mathbf{C_4}$] \emph{Expressive data model.}  The data model used to logically represent information is expressive and allows encoding multiple data types, data structures and data semantics.	This is the path investigated by RSP-QL~\cite{DellAglioDataScience2017,DBLP:conf/debs/ValleDM16}.
  \item[$\mathbf{C_5}$] \emph{Multiple representations.} The language is variety proof, in the sense that it ingests data in multiple representation and while offering a unified set of logical operators it includes physical operators able to process the various representations and delay as much as possible the usage of a common representation. See for instance, the most recent evolution of the Streaming Linked Data framework~\cite{DBLP:conf/esws/BalduiniV017a}. 
  \item[$\mathbf{C_6}$] \emph{New sources with new formats.} The language as well as it implementation should allow to add new sources where data are represented in a new form that was not foreseen when the language was released. The idea is to extend the approach of R2RML\footnote{\url{https://www.w3.org/TR/r2rml}} -- a language for expressing customized mappings from relational databases to RDF datasets -- to any data source of any format.
\end{itemize}

\textbf{Why is this difficult?}

A system, which has to tame data variety, has a tougher time in deriving value than a system, which has to handle a single well-structured data source. This is because solutions that analyse data require in input homogeneous well-formed data, but, when data variety is present, a number of different data management solutions must be used at the same time to prepare such a data. Moreover, each of those solution takes its time in performing its part of the processing as well as in coordinating with the other solutions. This time is particularly relevant in the stream processing domain, where answers should be generated within well-specified latency bounds. Even if the time available to answer depends on the application domain (in call centres, routing needs to be decided in sub-seconds, while in oil operations, the detection of dangerous situations must occur within minutes), still traditional pipelines for feature extraction and Extraction--Transformation--Load, may take so long
% to make the information available for analysis layer 
that the results, when computed, are no longer useful. For this reason, it is still extremely challenging to tame variety in stream precessing systems.

